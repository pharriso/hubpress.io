<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Cloud and Automation]]></title><description><![CDATA[This blog focuses mainly on Red Hat products in the Cloud and Automation space. I am currently working as a Solution Architect for Red Hat in the UK. ]]></description><link>http://cloudautomation.pharriso.co.uk</link><image><url>images/background.jpg</url><title>Cloud and Automation</title><link>http://cloudautomation.pharriso.co.uk</link></image><generator>RSS for Node</generator><lastBuildDate>Mon, 10 Feb 2020 19:17:46 GMT</lastBuildDate><atom:link href="http://cloudautomation.pharriso.co.uk/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Ansible Tower Dynamic Inventories - Manage Enabled Hosts]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>If you have used <a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/inventories.html#smart-inventories">dynamic inventories in Ansible Tower</a> before, you may have noticed that it adds some logic to determine whether a host should be enabled for job execution or not. For example, when syncing with our Red Hat Virtualisation environment, it has set some of our hosts to disabled.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower_inventory_disabled.png" alt="tower inventory disabled">
</div>
</div>
<div class="paragraph">
<p>Why do we get this behaviour? In the case of Red Hat Virtualisation you can probably tell from the screen shot - Tower will disable any VM&#8217;s which are powered off and we can see the VM&#8217;s which are disabled show a state of "status_down". For VMware, it will disable any VM&#8217;s where VMware tools isn&#8217;t reporting a guest state. A lot of the time this is really useful and can reduce job failures - why try to connect to a VM which is powered off? But, there may be times when you want to override this behaviour. For example, you might want to deploy VMware Tools to some guests, but they are being excluded from job execution. Another example we had recently was that we wanted to delete a bunch of VM&#8217;s in our Red Hat Virtualisation platform which were powered off, but they were being excluded - because they were powered off. Rather than powering on the VM&#8217;s so that we could delete them, we just amended the behaviour in Tower so that these VM&#8217;s weren&#8217;t marked as disabled.</p>
</div>
<div class="paragraph">
<p>To see how Tower determines if a node is enabled or disabled, you can take a look in <strong>/var/lib/awx/venv/awx/lib/python3.6/site-packages/awx/settings/defaults.py</strong></p>
</div>
<div class="paragraph">
<p>Looking at RHV (Upstream name is oVirt), we can see:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code># ---------------------
# ----- oVirt4 -----
# ---------------------
RHV_ENABLED_VAR = 'status'
RHV_ENABLED_VALUE = 'up'</code></pre>
</div>
</div>
<div class="paragraph">
<p>And for VMware:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code># Inventory variable name/values for determining whether a host is
# active in vSphere.
VMWARE_ENABLED_VAR = 'guest.gueststate'
VMWARE_ENABLED_VALUE = 'running'</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_changing_the_default_behaviour">Changing the default behaviour</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that we have seen the default settings and know the variable names, we can override the default behaviour. The easiest way to do this is to create a custom configuration file in /etc/tower/conf.d and override the variable value. For example, to enable all VM&#8217;s regardless of power status you could create the following file and set the RHV_ENABLED_VALUE to be empty:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code># cat /etc/tower/conf.d/custom.py
RHV_ENABLED_VALUE = ''</code></pre>
</div>
</div>
<div class="paragraph">
<p>After creating this configuration file, restart the tower services:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code># ansible-tower-service restart</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now when we sync the inventory we can now see that all of the hosts are enabled regardless of power state:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower_inventory_enabled.png" alt="tower inventory enabled">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary">Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ansible Tower tries to be helpful in the way it disables hosts that have been imported from dynamic inventories to try to avoid unnecessary job failures. If you need to configure this behaviour then you can follow the steps outlined above. These steps should not be confused with dynamic inventory filters, which will completely exclude a host from being imported into Ansible Tower.</p>
</div>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2020/02/10/Ansible-Tower-Dynamic-Inventories-Manage-Enabled-Hosts.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2020/02/10/Ansible-Tower-Dynamic-Inventories-Manage-Enabled-Hosts.html</guid><pubDate>Mon, 10 Feb 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[Ansible Constructed Inventory Plugin]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>In this blog post we will look at how we can easily enrich an existing dynamic inventory using the constructed inventory plugin. But, before we do that, let&#8217;s take a step back.</p>
</div>
<div class="paragraph">
<p>Ansible is a simple automation tool that allows users to achieve common use cases such as configuration management, provisioning and complex multi-tier orchestration. Part of what makes Ansible so simple, is the fact that it is agentless. One doesn&#8217;t need to deploy agents or any heavyweight control software to get up and running with Ansible automation. So, if Ansible is agentless, how does it know what nodes it should manage? We use an <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#inventory-basics-formats-hosts-and-groups">inventory</a> in Ansible to provide it with this list of managed nodes.</p>
</div>
<div class="paragraph">
<p>In it&#8217;s simplest form, an inventory is just an INI or YAML file which contains a list of our managed nodes. This is ideal when getting started with Ansible, but as you start to really use Ansible in anger and at scale you will probably face a couple of questions.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How do I classify my infrastructure so that I can be more selective in what devices I automate against?</p>
</li>
<li>
<p>How do I effectively and efficiently maintain a list of all of my managed nodes?</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The answer to both of these questions, can quite often be to use a <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html">dynamic inventory</a>. A dynamic inventory is a script or plugin which will go to a source of truth and discover the nodes I need to manage. It will also automatically classify the nodes by putting them into groups which can be used to more selectively target devices when automating with Ansible. There are a number of sources that Ansible can talk to out of the box such as VMware vCenter, AWS, GCP, Azure or Red Hat Satellite (Foreman upstream). There are also community inventory scripts such this the <a href="https://github.com/ServiceNowITOM/ansible-sn-inventory">ServiceNow CMDB</a> script.  And finally, you can <a href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html">develop your own</a> dynamic inventory. The benefit to me as a user of Ansible is quite clear. I now no longer need to maintain a list of managed nodes. As I add or remove managed nodes, the dynamic inventory will continue to provide me with an up to date list.</p>
</div>
<div class="paragraph">
<p>But the dynamic inventory scripts and plugins also provide us with another benefit. They provide rich information about our managed nodes and the environment they are running in. This information is made available to us in the form of variables which we can use in our automation. For example, if we use the AWS (EC2) inventory plugin, then we will retrieve variables for each discovered device such as private IP addresses, regions, security groups and so on.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_dynamic_inventory_example">Dynamic Inventory Example</h3>
<div class="paragraph">
<p>Let&#8217;s look at an example of an inventory plugin to see what type of information it returns. I&#8217;m going to look at the Red Hat Satellite/Foreman plugin. <a href="https://www.redhat.com/en/technologies/management/satellite">Red Hat Satellite</a> is a tool that is often used for managing RHEL content and patching of RHEL servers. The plugin is actually called foreman because foreman is one of the upstream components in Red Hat Satellite.</p>
</div>
<div class="paragraph">
<p>Here are the contents of my inventory plugin file. We have a plaintext password here but we&#8217;ll see how we can avoid that later with Ansible Tower.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>plugin: foreman
url: https://sat6.demolab.local
user: sat-tower
password: Redhat123
validate_certs: False</code></pre>
</div>
</div>
<div class="paragraph">
<p>Below is a list of the groups that are returned by my Satellite server. For example, we can see a group called foreman_hostgroup_prod_web which contains two hosts - prod-web1.demolab.local and prod-web2.demolab.local. This is because I have a hostgroup in Satellite which these two servers are members of.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>ansible-inventory -i foreman.yaml --graph

@all:
  |--@foreman_dev_web:
  |  |--dev-web1.demolab.local
  |--@foreman_prod_haproxy:
  |  |--lb.demolab.local
  |--@foreman_prod_web:
  |  |--prod-web1.demolab.local
  |  |--prod-web2.demolab.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>As well as the groupings, we also get a number of facts from Satellite. Again, here are some snippets from one of the hosts:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>ansible-inventory -i foreman.yaml --host prod-web1.demolab.local

    "foreman_subscription_facet_attributes": {
        "autoheal": true,
        "id": 4883,
        "last_checkin": "2020-01-14 02:08:23 UTC",
        "purpose_addons": [],
        "purpose_role": null,
        "purpose_usage": null,
        "registered_at": "2019-12-10 10:21:03 UTC",
        "registered_through": "sat6.demolab.local",
        "release_version": null,
        "service_level": "",
        "user": null,
        "uuid": "3a9c2c19-57e4-4f98-b675-99d50d2d5b1e"


        "lifecycle_environment_name": "Prod",
        "upgradable_module_stream_count": 0,
        "upgradable_package_count": 0,
...

    "foreman_location_name": "London",
...

    "foreman_organization_name": "Red Hat",

...
    "foreman_ip": "10.50.0.31",</code></pre>
</div>
</div>
<div class="paragraph">
<p>This is just a fraction of the information we get from the inventory source, but we can see lot&#8217;s of useful information here about the subscription status, available errata and other foreman objects. These facts are actually host_vars which we can use in our automation.</p>
</div>
</div>
<div class="sect2">
<h3 id="_how_can_we_construct_additional_data">How can we "construct" additional data?</h3>
<div class="paragraph">
<p>So far we have been talking about pretty standard stuff with regards inventories. We&#8217;ve seen the type of facts and groups we get back from the foreman inventory plugin. But what if we want to dynamically create more groups based on the facts that we are getting back? Of course, if you have the necessary skills then you can modify the inventory plugin to return the information that you need. But, you may not need to do that. There is a really useful inventory plugin which serves this purpose. The <a href="https://docs.ansible.com/ansible/latest/plugins/inventory/constructed.html">constructed</a> inventory plugin takes information from another inventory source and uses that to construct new groups and variables. I really like this because it allows us to keep Ansible simple and avoid writing code if we don&#8217;t want to.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s use our foreman example above to construct some new groups. As an example use case, let&#8217;s say I want to group hosts based on the Satellite node they are registred through. This would potentially allow me to identify which datacenter or network zone they are in which could be useful if I need to use a jump host to allow Ansible to manage them. Looking at the output above, we can see that this information is available as a variable:</p>
</div>
<div class="paragraph">
<p><strong>foreman_subscription_facet_attributes.registered_through</strong></p>
</div>
<div class="paragraph">
<p>I&#8217;m also going to group based on lifecycle environment in Satellite - so Prod or Dev in my case.</p>
</div>
<div class="paragraph">
<p>For that I need the following variable:</p>
</div>
<div class="paragraph">
<p><strong>foreman_content_facet_attributes.lifecycle_environment_name</strong></p>
</div>
</div>
<div class="sect2">
<h3 id="_example_1_generating_new_groups">Example 1 - Generating new groups</h3>
<div class="paragraph">
<p>We need a directory for our foreman inventory plugin to live in so that we can source multiple inventory plugins or scripts.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>inventories/
├── foreman_constructed.yml
└── foreman.yml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>NOTE</strong> the constructed inventory plugin relies on data from another inventory  source so we need the foreman.yml plugin to be invoked before the constructed inventory. When sourcing a directory as an Ansible inventory they are executed alphabetically. More information can be found <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#using-multiple-inventory-sources">here</a></p>
</div>
<div class="paragraph">
<p>Here are the contents of my foreman_constructed.yml file.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>plugin: constructed
strict: False
keyed_groups:
  -  prefix: ""
     separator: ""
     key: foreman_subscription_facet_attributes.registered_throug
  -  prefix: ""
     separator: ""
     key: foreman_content_facet_attributes.lifecycle_environment_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we can source the directory which will incorporate both inventory sources:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>ansible-inventory -i inventories/ --graph
@all:
  |--@Dev:
  |  |--dev-web1.demolab.local
  |--@Prod:
  |  |--lb.demolab.local
  |  |--prod-web1.demolab.local
  |  |--prod-web2.demolab.local
  |--@foreman_dev_web:
  |  |--dev-web1.demolab.local
  |--@foreman_prod_haproxy:
  |  |--lb.demolab.local
  |--@foreman_prod_web:
  |  |--prod-web1.demolab.local
  |  |--prod-web2.demolab.local
  |--@sat6_demolab_local:
  |  |--dev-web1.demolab.local
  |  |--lb.demolab.local
  |  |--prod-web1.demolab.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note the new groups we now have available to us. I can now target these new groups or assign variables to them using group_vars.</p>
</div>
</div>
<div class="sect2">
<h3 id="_example_2_generating_new_variables">Example 2 - Generating new variables</h3>
<div class="paragraph">
<p>As well as generating new groups, the constructed inventory plugin can also be used to "compose" new variables. For this example, I am going to use the IP address that Satellite provided me with <strong>foreman_ip</strong> variable to set the <strong>ansible_host</strong> variable.</p>
</div>
<div class="paragraph">
<p>The complete foreman_constructed.yml file now looks as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>plugin: constructed
strict: False
compose:
     ansible_host: foreman_ip
keyed_groups:
  -  prefix: ""
     separator: ""
     key: foreman_subscription_facet_attributes.registered_through
  -  prefix: ""
     separator: ""
     key: foreman_content_facet_attributes.lifecycle_environment_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>This results in the ansible_host variable being set:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>ansible-inventory -i inventories/ --host prod-web1.demolab.local

{
    "ansible_host": "10.50.0.31",</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_using_the_constructed_inventory_in_tower">Using the constructed inventory in Tower</h3>
<div class="paragraph">
<p>I&#8217;ve been using Ansible Engine and the command line so far. But what happens if I am using Ansible Tower for my Ansible automation. The good news is that using a constructed inventory in Ansible Tower is straight forward. We will source the inventory plugins from a source control repository. This ensures I can use source control branching techniques to maintain control over any changes before they are pushed to production.</p>
</div>
<div class="paragraph">
<p>My source control repository has the same structure as before with the exception that I no longer need the foreman.ini file. This is because I will pass my credentials from Tower. The repository is <a href="https://github.com/pharriso/ansible_constructed_inventory">here</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>inventories/
├── foreman_constructed.yml
└── foreman.yml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Also, note how the foreman.yml file no longer contains a username, password or Satellite server URL.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>plugin: foreman
validate_certs: False</code></pre>
</div>
</div>
<div class="paragraph">
<p>We will use Ansible Tower&#8217;s credential management capabilities to pass these details to the inventory plugin. But, first we need to create a project in Tower which will pull in our inventory files from source control.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/constructed-tower-project.png" alt="constructed tower project">
</div>
</div>
<div class="paragraph">
<p>As previously mentioned, we are going to use <a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/credentials.html">Ansible Tower&#8217;s credential management</a> to store all of the credentials that we need to talk to our Satellite server. We need to define a custom credential type to talk to Satellite for the purpose of our inventory plugin. In the Tower UI, Navigate to <strong>Credential Types</strong> and add a new credential with the following details:</p>
</div>
<div class="listingblock">
<div class="title">INPUT CONFIGURATION</div>
<div class="content">
<pre class="highlight"><code>fields:
  - id: FOREMAN_USER
    type: string
    label: Username
  - id: FOREMAN_PASSWORD
    type: string
    label: Password
    secret: true
  - id: FOREMAN_SERVER
    type: string
    label: Satellite Server
required:
  - FOREMAN_USER
  - FOREMAN_PASSWORD
  - FOREMAN_SERVER</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">INJECTOR CONFIGURATION</div>
<div class="content">
<pre class="highlight"><code>env:
  FOREMAN_PASSWORD: '{{ FOREMAN_PASSWORD }}'
  FOREMAN_SERVER: '{{ FOREMAN_SERVER }}'
  FOREMAN_USER: '{{ FOREMAN_USER }}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can look at the docs page for the various inventory plugins to understand what variables they expect. An example with a snippet of output can be seen below for the foreman plugin:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>ansible-doc -t inventory foreman

= user
        foreman authentication user

        set_via:
          env:
          - name: FOREMAN_USER</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now that we have a credential type in Ansible Tower, we can create a credential using this new type.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/constructed-tower-credential.png" alt="constructed tower credential">
</div>
</div>
<div class="paragraph">
<p>Next we need to create an inventory:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/constructed-tower-inventory.png" alt="constructed tower inventory">
</div>
</div>
<div class="paragraph">
<p>Then we can add an inventory source to the inventory. Ensure to add the correct credential that we created earlier.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/constructed-tower-inventory-source.png" alt="constructed tower inventory source">
</div>
</div>
<div class="paragraph">
<p>Once the inventory source has finished syncing, we should see that the relevant hosts have been imported with the constructed groups and composed variables.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/constructed-tower-inventory-groups.png" alt="constructed tower inventory groups">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary">Summary</h3>
<div class="paragraph">
<p>The constructed inventory plugin can be really useful for manipulating the information returned from existing dynamic inventory plugins and scripts. This example used a plugin but the constructed inventory plugin works in the same way with inventory scripts. It is worth noting that some inventory plugins provide in-built capabilities to construct variables and generate groups. Check the <a href="https://docs.ansible.com/ansible/latest/plugins/inventory.html#plugin-list">inventory plugins</a> before deciding if you need to also use the constructed inventory plugin.</p>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2020/01/16/Ansible-Constructed-Inventory-Plugin.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2020/01/16/Ansible-Constructed-Inventory-Plugin.html</guid><pubDate>Thu, 16 Jan 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[Call Ansible Tower from ServiceNow]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>In this post we will look at how we can call Ansible Tower from ServiceNow as part of a ServiceNow Catalog Request. For this example, I have a <a href="https://github.com/pharriso/ansible_network_demo/blob/master/bigip_pool_member_snow.yml">playbook</a> in Ansible Tower that will manage the membership of a node within an F5 loadbalancer pool. The playbook expects the user to input the name of the node that should be managed and the state it should be in - either enabled or forced_offline. So we need to pass these variables from ServiceNow to Ansible Tower. Note that the playbook will also close down the ServiceNow request to fully automate the process without any manual intervention.</p>
</div>
<div class="paragraph">
<p>This integration allows us to use Tower for what it does best - provide the enterprise platform for executing our Ansible playbooks. We can leave Tower to manage credentials, provide RBAC and capture the audit history. At the same time we can leverage existing processes within ServiceNow like approval processes and general change management workflows.</p>
</div>
<div class="paragraph">
<p><strong>NOTE</strong> I am not a ServiceNow developer and this is definitely not a tutorial in how best to use ServiceNow. This is something that I had to work out for a demo around Ansible Tower.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ansible_tower_job_template">Ansible Tower Job Template</h3>
<div class="paragraph">
<p>I already have my <a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/job_templates.html">job template</a> defined in Ansible Tower. Make a note of the job ID which is displayed in the URL when you click on the Job Template in Tower. For example the job ID is 10 in this sample URL - <a href="https://tower.example.com/#/templates/job_template/10" class="bare">https://tower.example.com/#/templates/job_template/10</a></p>
</div>
<div class="paragraph">
<p>To allow extra variables to be passed into the Ansible job execution, I need to enable <strong>Prompt on launch</strong> for <strong>extra variables</strong> as per the screenshot below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_tower_job_template.png" alt="snow tower job template">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tower_with_self_signed_certs">Tower with self-signed certs</h3>
<div class="paragraph">
<p>As I am using a self-signed certificate in my instance, I need to configure ServiceNow to not verify the hostname in the certificate. To do this, search for <strong>sys_properties.list</strong> in the filter navigator. Then search for <strong>com.glide.communications.httpclient.verify_hostname</strong> and set it to false.</p>
</div>
</div>
<div class="sect2">
<h3 id="_servicenow_outbound_rest_message">ServiceNow Outbound REST Message</h3>
<div class="paragraph">
<p>The first thing we need to configure in ServiceNow, is an Outbound REST message. This defines how it will connect to the Ansible Tower API to launch a job. This includes the API call, credentials and any extra variables we might want to pass from ServiceNow to Ansible Tower.</p>
</div>
<div class="paragraph">
<p>In ServiceNow, navigate to <strong>System Web Services &#8594; Outbound &#8594; REST Message</strong> and click <strong>New</strong>.</p>
</div>
<div class="paragraph">
<p>Enter a name and the URL for the REST endpoint. This should be your Ansible Tower URL with the job ID that you want to launch.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_rest_name.png" alt="snow rest name">
</div>
</div>
<div class="paragraph">
<p>Set the <strong>Authentication type</strong> to <strong>basic</strong> and then click on the magnifying glass next to <strong>Basic Auth profile</strong>. Click <strong>New</strong> and enter a name for credential &amp; the username and password to authenticate to Tower.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_cred.png" alt="snow cred">
</div>
</div>
<div class="paragraph">
<p>Next set the Content-Type by selecting the <strong>HTTP Request</strong> tab and then adding a new <strong>HTTP Header</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_endpoint_http_request.png" alt="snow endpoint http request">
</div>
</div>
<div class="paragraph">
<p>Click submit and then go back into your REST Message. As mentioned earlier, I want to pass variables from ServiceNow to Ansible Tower so I can use them in my Ansible automation. To do this, I need to add some content to the HTTP Post. Under <strong>HTTP Methods</strong> click <strong>New</strong> and add the details for our POST Request.  The <strong>HTTP Method</strong> needs to be <strong>POST</strong> and the <strong>Endpoint</strong> needs to be the url for the job we are launching.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_post.png" alt="snow post">
</div>
</div>
<div class="paragraph">
<p>Now under the <strong>HTTP Request</strong> tab, add a new <strong>HTTP Query Parameter</strong> with a <strong>Name</strong> of <strong>Content</strong> and a <strong>Value</strong> which contains the variable data I will pass to Tower. In my example:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>{"extra_vars": { "member_name": "${f5_member}", "snow_request": "${snow_request}", "member_state": "${f5_member_state}" } }</pre>
</div>
</div>
<div class="paragraph">
<p>Note the <strong>${snow_request}</strong> variable here. We will come back to that later.</p>
</div>
<div class="paragraph">
<p>The <strong>HTTP Query Parameter</strong> should look as follows.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_extra_vars.png" alt="snow extra vars">
</div>
</div>
<div class="paragraph">
<p>Now we have defined how ServiceNow will make an API call to Ansible Tower. We need to create a workflow to define how this API call will be triggered.</p>
</div>
</div>
<div class="sect2">
<h3 id="_servicenow_workflow">ServiceNow Workflow</h3>
<div class="paragraph">
<p>In ServiceNow, navigate to <strong>Workflow &#8594; Editor</strong>. Select <strong>New Workflow</strong>. Name the workflow and set the table to <strong>Requested Item [sc_req_item]</strong>. Press submit and you will be taken into the workflow design canvas.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_workflow_name.png" alt="snow workflow name">
</div>
</div>
<div class="paragraph">
<p>Delete the connector between Begin and End. Then Select the <strong>Core</strong> tab in the right hand pane. Under <strong>Utilities</strong>, drag the <strong>Run Script</strong> object onto the workflow canvas. Name the script and then paste the script contents in.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>try {
 var r = new sn_ws.RESTMessageV2('Tower Job Launch', 'F5 Member Job'); <i class="conum" data-value="1"></i><b>(1)</b>
 r.setStringParameterNoEscape('f5_member', current.variables.f5_member);  <i class="conum" data-value="2"></i><b>(2)</b>
 r.setStringParameterNoEscape('f5_member_state', current.variables.f5_member_state);
 r.setStringParameterNoEscape('snow_request', current.request.number);  <i class="conum" data-value="3"></i><b>(3)</b>

 var response = r.execute();
 var responseBody = response.getBody();
 var httpStatus = response.getStatusCode();
}
catch(ex) {
 var message = ex.message;
}</pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The name of the Outbound REST Message and HTTP Method name.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Example variable that will be passed from Catalog request.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>This is a special var we are determining from the ServiceNow catalog request. We will pass the request number that is created by the user as a variable called <strong>snow_request</strong></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Now let&#8217;s drag an approval task onto our workflow. Again, in the <strong>Core</strong> tab, drag the <strong>Approval User</strong> or <strong>Approval Group</strong> item across. Name the approval step and select the user or group that needs to approve.</p>
</div>
<div class="paragraph">
<p>Finally, let&#8217;s connect our workflow up. Drag from small orange box inside <strong>Begin</strong> to your <strong>Approval</strong> task. Then drag from <strong>Approved</strong> to our <strong>Run Script</strong>. Then drag from <strong>Rejected</strong> to <strong>End</strong>. Lastly, drag from the <strong>Script</strong> to <strong>End</strong>. The flow should look as follows.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_workflow_image.png" alt="snow workflow image">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_servicenow_service_catalog">ServiceNow Service Catalog</h3>
<div class="paragraph">
<p>Now that we have defined out outbound REST call and our workflow, we can add a Service Catalog item to expose this to end users. In ServiceNow, navigate to <strong>Service Catalog &#8594; Catalog Definitions &#8594; Maintain Items</strong>. Click on <strong>New</strong> and enter a name for the Service Catalog item. Select the <strong>Catalogs</strong> you want the item to appear in. I have just selected <strong>Service Catalog</strong> for this example. Then in the <strong>Process Engine</strong> tab, search for your workflow.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_service_request_workflow.png" alt="snow service request workflow">
</div>
</div>
<div class="paragraph">
<p>Now we can define the information we want to prompt the user for which will be passed to Ansible Tower as variables. Within your Catalog Item, navigate to the <strong>Variables</strong> tab at the bottom of the screen. Click <strong>New</strong> to define a new variable.</p>
</div>
<div class="paragraph">
<p>Select the question <strong>Type</strong> e.g. single line text or multi-choice. Then enter the question you want the user to see in the Catalog item in the <strong>Question</strong> field. In the <strong>Name</strong> field, enter the name of the variable that you want to pass to Tower.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_sc_var.png" alt="snow sc var">
</div>
</div>
<div class="paragraph">
<p>For multi-choice variables, you need to add <strong>Question Choices</strong> at the bottom of this screen. The <strong>Text</strong> being what you want the user to see on the form and the <strong>Value</strong> being the value of the variable that will be passed to Tower.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/snow_sc_question_choices.png" alt="snow sc question choices">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_executing_the_workflow">Executing the workflow</h3>
<div class="paragraph">
<p>So what should happen when we order this Catalog item?</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The user is prompted for the name of the host they want to manage in the F5 loadbalancer and the desired state of that host - enabled or forced_offline.</p>
</li>
<li>
<p>The request is raised and will await approval.</p>
</li>
<li>
<p>Once the request is approved ServiceNow will launch the playbook via the Tower API. The answers that the user provided in the catalog request will be passed as variables to the Ansible Tower playbook. We will also pass the ServiceNow request number.</p>
</li>
<li>
<p>Ansible will manage the host in the F5 loadbalancer pool as requested by the user.</p>
</li>
<li>
<p>Ansible will update the ticket in ServiceNow to say what has happened and close the ticket.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can watch a recording of this below.</p>
</div>
<div class="videoblock">
<div class="content">
<iframe src="https://www.youtube.com/embed/BcoffUF9Yhg?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_acknowledgements">Acknowledgements</h3>
<div class="paragraph">
<p>There were two excellent guides I used for this. I just wanted to piece the best bits from both guides together:</p>
</div>
<div class="paragraph">
<p><a href="https://liveaverage.com/blog/ansible-tower-and-servicenow-integration-in-10-minutes/" class="bare">https://liveaverage.com/blog/ansible-tower-and-servicenow-integration-in-10-minutes/</a></p>
</div>
<div class="paragraph">
<p><a href="https://github.com/eanylin/ansible-lab/tree/master/servicenow_demo/" class="bare">https://github.com/eanylin/ansible-lab/tree/master/servicenow_demo/</a></p>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2019/08/05/Call-Ansible-Tower-from-Service-Now.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2019/08/05/Call-Ansible-Tower-from-Service-Now.html</guid><pubDate>Mon, 05 Aug 2019 00:00:00 GMT</pubDate></item><item><title><![CDATA[Scaling Ansible Tower - Job slicing]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Ansible Tower is a centralised platform for running and controlling your Ansible automation. It provides a number of key features for running Ansible in the enterprise.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Role-Based Access Control</p>
</li>
<li>
<p>Inventory Management</p>
</li>
<li>
<p>Credential Management</p>
</li>
<li>
<p>Auditing &amp; Logging</p>
</li>
<li>
<p>Clustering &amp; Scale-Out</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Job slicing is a new scale-out feature that was introduced in Ansible Tower 3.4 which allows us to run jobs that are distributed across our Ansible Tower cluster. Before we look at job slicing let&#8217;s quickly look at  clustering and job distribution within a cluster.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ansible_tower_clustering">Ansible Tower clustering</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ansible Tower can be installed in a cluster to provide a highly available platform for running Ansible. A clustered install provides scale-out capabilities in that different jobs are scheduled across Tower nodes to ensure they are sharing the load. However, each individual job is run on a single Tower node only. If I run a job against 1000&#8217;s of servers then a single Tower node runs this job and it must have enough capacity to run this job in a timely fashion. Let&#8217;s look at how we calculate concurrency and capacity in Ansible Tower.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_calculating_capacity">Calculating Capacity</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ansible uses forks to determine how many hosts to automate against in parallel. By default 5 forks are spawned but we can override this if we are automating against a large number of hosts. For example, I may run a configuration management playbook every 1 hour to ensure my hosts are in a desired state. If I run that playbook against 1000&#8217;s of nodes with only 5 forks then this will take some time to complete.</p>
</div>
<div class="paragraph">
<p>We can calculate the number of available forks based on memory capacity or cpu capacity depending on the nature of the workload.</p>
</div>
<div class="paragraph">
<p><strong>memory capacity</strong></p>
</div>
<div class="paragraph">
<p>Protecting memory capacity is the default configuration and allows us to overcommit cpu while ensuring we don&#8217;t run out of memory. To calculate the number of forks we remove 2048MB memory for the running of Tower services and then divide the remaining available memory by <strong>mem_per_fork</strong> - which defaults to 100MB:</p>
</div>
<div class="paragraph">
<p><code>(mem - 2048) / mem_per_fork</code></p>
</div>
<div class="paragraph">
<p>For a Tower node with 4GB memory this results in a capacity of around 20 forks:</p>
</div>
<div class="paragraph">
<p><code>(4096 - 2048) / 100 = 20</code></p>
</div>
<div class="paragraph">
<p><strong>cpu capacity</strong></p>
</div>
<div class="paragraph">
<p>For cpu capacity we multiply the number of cpus by <strong>fork_per_cpu</strong> - which defaults to 4.</p>
</div>
<div class="paragraph">
<p><code>cpus * fork_per_cpu</code></p>
</div>
<div class="paragraph">
<p>For a Tower node with 4 cores:</p>
</div>
<div class="paragraph">
<p><code>4 * 4 = 16</code></p>
</div>
<div class="paragraph">
<p>If I were to run a job with more forks than the calculated capacity, then I run the risk of performance issues or running out of resources on my Tower nodes.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_job_slicing">Job Slicing</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As previously mentioned, when a job is launched in Ansible Tower, it is executed on a single node in the cluster. So effectively, ansible-playbook is run from a single node. This means that a job is limited to the number of forks on a single Tower node. If we are executing a playbook across a large number of hosts then we are not making use of all of the available capacity in our cluster.</p>
</div>
<div class="paragraph">
<p>Job slicing is a new feature of Ansible Tower 3.4 and helps to address this issue. Job slicing allows us to distribute a job across multiple Tower nodes. It does this by splitting the inventory into slices. A workflow is then created for us with multiple instances of our job being run on each slice of our inventory. For example, if I have 30 nodes in my inventory and I decide to create 3 slices then a workflow is created with three jobs - each being executed on 10 nodes in parallel. Obviously, I need 3 Tower nodes in this example so that my three job slices can be executed across the three hosts.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_job_slices">Using job slices</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To demonstrate job slicing, I have a three node Tower cluster. My inventory contains 49 hosts for me to automate against. Here is the available capacity in forks reported by my hosts.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/tower%20capacity.png" alt="tower capacity">
</div>
</div>
<div class="paragraph">
<p>My Tower hosts can each safely spawn up to 27 forks based on memory capacity. If we look at the following job template we can see that I have specified 30 forks - I run the risk of exhausting memory resources. Also note that I only have one job slice configured - this is the default when creating a new job template.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/job%20template%201%20slice.png" alt="job template 1 slice">
</div>
</div>
<div class="paragraph">
<p>When I launch my job we can see that my playbook is being run on a single Tower node. As I have allocated more forks than I safely have capacity for I am over-allocated on capacity. My other two Tower nodes are just relaxing at this point with no work scheduled on them.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/1%20slice%20capacity.png" alt="1 slice capacity">
</div>
</div>
<div class="paragraph">
<p>Now I&#8217;ll re-configure my job template so that it utilises three slices.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/job%20template%203%20slices.png" alt="job template 3 slices">
</div>
</div>
<div class="paragraph">
<p>This time when I launch my job template, a worklfow is automatically generated.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/job%20slice%20workflow%20finished.png" alt="job slice workflow finished">
</div>
</div>
<div class="paragraph">
<p>If we look at one of the individual jobs within the workflow we can see that this is slice job 1 of 3. Also, note that this job is being run on a "slice" of my inventory - 16 hosts.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/job%20output.png" alt="job output">
</div>
</div>
<div class="paragraph">
<p>Finally, we can see that capacity is now being utilised across all three of my Tower nodes.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/tower%20slice/3%20slice%20capacity.png" alt="3 slice capacity">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary">Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Job slices provide an additional method for scaling Ansible automation with Ansible Tower. By default, jobs are distributed across Tower nodes in a cluster but each individual job is only ever run from a single Tower node. Job slicing allows us to split a single job so that it is run across multiple nodes to provide additional scale-out capacity.</p>
</div>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2019/04/17/Scaling-Ansible-Tower-Job-slicing.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2019/04/17/Scaling-Ansible-Tower-Job-slicing.html</guid><pubDate>Wed, 17 Apr 2019 00:00:00 GMT</pubDate></item><item><title><![CDATA[RHV Disaster Recovery - Part II]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>In <a href="https://cloudautomation.pharriso.co.uk/2019/01/08/RHV-Disaster-Recovery-Part-I.html">part one</a> of this blog we looked at the different Disaster Recovery Solutions for RHV. In this part, we will look at the Active/Passive implementation in more detail, including how to set it up and run it. You&#8217;ll also find a recorded demo of the failover process.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_overview">Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A quick recap on what was discussed in part one of this blog. The Active/Passive architecture allows us to fail Virtual Machines over to a Disaster Recovery site in the event of a failure in the Primary site. The solution also provides the necessary orchestration to failback to the Primary site when appropriate. We leverage the power of Ansible to orchestrate the failover. The necessary Ansible roles are provided in a rpm called ovirt-ansible-disaster-recovery which is shipped as part of the RHV product.</p>
</div>
<div class="paragraph">
<p>From an underlying infrastructure perspective, we obviously need some hypervisors in our DR site to fail the workloads onto. The DR site also needs it&#8217;s own RHV Manager. We also rely on replicated storage between sites. The orchestration of the storage replication is not covered by the Ansible roles that are shipped with RHV. A storage administrator needs to setup the replication beforehand. They will also need to make the storage read/write in the secondary site at the point that DR is invoked.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s take a high-level view of the DR process. In advance of the disaster, one must generate the mapping file which maps entities from the Primary site to the DR site. For example, workloads in "Cluster1" in the Primary site should be failed over to "Cluster2" in my DR site. This mapping file is used during the failover and failback process.</p>
</div>
<div class="paragraph">
<p>In the event of a disaster, the storage must be made read/write in the DR site. The process for this will vary depending on the nature of the disaster and the type of storage. The "failover" Ansible playbook can then be run. This will mount the storage domains at the DR site. Virtual Machines are then registered and started. Any VM&#8217;s marked as Highly Available are started first.</p>
</div>
<div class="paragraph">
<p>Once the Primary site is brought back online, it must be prepared. This is part of the "clean" Ansible playbook. Any replicated storage domains need to be removed from the RHV Manager. A storage administrator will need to ensure replication is now taking place from the DR site to the Primary site.</p>
</div>
<div class="paragraph">
<p>When ready, the failback playbook can be run. This stops the VM&#8217;s in the DR site and removes the storage domains from the RHV Manager. The playbook then pauses and waits for the administrator to confirm that replication has been stopped and the storage is now read/write in the Primary site. Once confirmed, the playbook will import the storage domains at the Primary site, register the VM&#8217;s and start them up. The final step is to ensure the storage replication is switched so that the Primary site is once again replicating to the DR site.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_demo_environment">Demo Environment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>I am using nested virtualisation for my lab. For the storage replication, I am using GlusterFS and geo-replication. This is asynchronous replication which is <strong>not</strong> recommended but it serves the purpose for this demo. Synchronous replication is recommended for replication between sites.</p>
</div>
<div class="paragraph">
<p>Each "site" has a RHV Manager. The RHV Manager is configured with a single cluster containing a singe RHV Host. I&#8217;ve got two small cirros VM&#8217;s which I will failover in this demo. One is marked as Highly Available to demonstrate the fact that HA VM&#8217;s are started before standard VM&#8217;s.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/RHV%20DR%20Active%20Passive%20Lab.png" alt="RHV DR Active Passive Lab">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_setup">Setup</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>All of the files mentioned in this setup section are available in my github repo <a href="https://github.com/pharriso/rhv-dr">here</a></em>.</p>
</div>
<div class="paragraph">
<p><strong>Don&#8217;t worry. All of the below playbooks are fully documented in the Red Hat documentation for RHV DR.</strong></p>
</div>
<div class="sect2">
<h3 id="_generate_mapping">Generate Mapping</h3>
<div class="paragraph">
<p>First create a variable file containing the passwords for the RHV manager. I&#8217;m creating a file called passwords.yml here with these contents:</p>
</div>
<div class="listingblock">
<div class="title">passwords.yml</div>
<div class="content">
<pre class="highlight"><code>---
dr_sites_primary_password: Redhat123
dr_sites_secondary_password: Redhat123</code></pre>
</div>
</div>
<div class="paragraph">
<p>Encrypt the file with ansible-vault to avoid leaving passwords in plaintext.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>ansible-vault encrypt password.yml</pre>
</div>
</div>
<div class="paragraph">
<p>Now we can create the playbook that will generate the mapping file for us.</p>
</div>
<div class="listingblock">
<div class="title">generate_mappings.yml</div>
<div class="content">
<pre class="highlight"><code>---
- name: Generate mapping
  hosts: localhost
  connection: local

  vars:
    site: https://rhvm-primary.example.com/ovirt-engine/api
    username: admin@internal
    password: "{{ dr_sites_primary_password }}"
    ca: /root/DR/primary_ca.pem
    var_file: disaster_recovery_vars.yml

  vars_files:
    - passwords.yml

  roles:
    - oVirt.disaster-recovery</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now run the playbook to generate the mapping variable file. This will log into the RHV Manager at the Primary site and retrieve details on components such as storage, networking and clusters.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>ansible-playbook generate_mappings.yml --tags generate_mapping --ask-vault-pass</pre>
</div>
</div>
<div class="paragraph">
<p>A file called disaster_recovery_vars.yml is generated. This needs to be edited to allow you to map components from the Primary site to the Disaster site. For example, the login details for the Disaster site:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>dr_sites_primary_url: https://rhvm-primary.example.com/ovirt-engine/api
dr_sites_primary_username: admin@internal
dr_sites_primary_ca_file: /root/DR/primary_ca.pem

# Please fill in the following properties for the secondary site:
dr_sites_secondary_url:  https://rhvm-secondary.example.com/ovirt-engine/api
dr_sites_secondary_username:  admin@internal
dr_sites_secondary_ca_file: /etc/pki/ovirt-engine/ca.pem</pre>
</div>
</div>
<div class="paragraph">
<p>And also the cluster mappings:</p>
</div>
<div class="literalblock">
<div class="content">
<pre># Mapping for cluster
dr_cluster_mappings:
- primary_name: Primary
  # Fill the correlated cluster name in the secondary site for cluster 'Primary'
  secondary_name: Disaster</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_create_failover_failback_playbooks">Create Failover/Failback Playbooks</h3>
<div class="paragraph">
<p>Now we can create the playbook that we will use to initiate the failover from our Primary site to our DR site:</p>
</div>
<div class="listingblock">
<div class="title">failover.yml</div>
<div class="content">
<pre class="highlight"><code>---
- name: Failover RHV
  hosts: localhost
  connection: local
  vars:
    dr_target_host: secondary
    dr_source_map: primary
  vars_files:
    - disaster_recovery_vars.yml
    - passwords.yml
  roles:
    - oVirt.disaster-recovery</code></pre>
</div>
</div>
<div class="paragraph">
<p>And the failback playbook to allow us to failback to our Primary site once it has been restored (The same playbook but with the source and target reversed):</p>
</div>
<div class="listingblock">
<div class="title">failback.yml</div>
<div class="content">
<pre class="highlight"><code>---
- name: Failback RHV
  hosts: localhost
  connection: local
  vars:
    dr_target_host: primary
    dr_source_map: secondary
  vars_files:
    - disaster_recovery_vars.yml
    - passwords.yml
  roles:
    - oVirt.disaster-recovery</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, the cleanup playbook. This is used to clean the Primary site ready for failback:</p>
</div>
<div class="listingblock">
<div class="title">clean_primary.yml</div>
<div class="content">
<pre class="highlight"><code>---
- name: clean RHV
  hosts: localhost
  connection: local
  vars:
    dr_source_map: primary
  vars_files:
    - disaster_recovery_vars.yml
  roles:
    - oVirt.disaster-recovery</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_failover">Failover</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To failover we need to ensure that the storage replication is stopped and is made read/write in the DR site. Once this is confirmed, we can run the Ansible playbook to failover.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>ansible-playbook failover.yaml --tags fail_over --ask-vault-pass</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_cleanup_and_failback">Cleanup and Failback</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Once the Primary site is brought back online we can begin the failback process. Storage now needs to be replicated from DR site back to Primary site. The primary site also needs to be cleaned to ensure storage domains are not imported.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>ansible-playbook clean_primary.yml --tags clean_engine --ask-vault-pass</pre>
</div>
</div>
<div class="paragraph">
<p>When ready, initiate the failback. The playbook will pause and wait for you to confirm that the storage replication has been stopped and that storage domains are now read/write in the Primary site.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>ansible-playbook failback.yml --tags fail_back --ask-vault-pass</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_demo">Demo</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following video demonstrates the failover process.</p>
</div>
<div class="videoblock">
<div class="content">
<iframe src="https://www.youtube.com/embed/OC66G7_y8Vo?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2019/01/16/RHV-Disaster-Recovery-Part-II.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2019/01/16/RHV-Disaster-Recovery-Part-II.html</guid><pubDate>Wed, 16 Jan 2019 00:00:00 GMT</pubDate></item><item><title><![CDATA[Infrastructure Migration Solution]]></title><description><![CDATA[<div class="paragraph">
<p>While VMware is undoubtedly a great virtualisation offering (I spent a number of users working with VMware tech) some customers are looking beyond traditional virtualisation. The growing adoption of containerisation is a great example of this and using RHV as a stepping stone to Container Native Virtualisation (CNV) is a good example use case.</p>
</div>
<div class="paragraph">
<p>Other customers simply want to save costs and are looking at alternative virtualisation offerings. Whatever the reason for moving from VMware, we need a method for migrating workloads to RHV.</p>
</div>
<div class="paragraph">
<p>This is what our Infrastructure Migration Solution (IMS) provides. A simple method for migrating workloads from VMware to RHV. We use a tool called CloudForms to drive the migration process (ManageIQ is the upstream project for CloudForms).</p>
</div>
<div class="paragraph">
<p>CloudForms is a manager of managers and can interact with various endpoints which are known as providers. A provider could be VMware vSphere, Red Hat Virtualisation, AWS, OpenStack etc. CloudForms is able to ingest information from these providers such as configuration details and performance metrics as well as orchestrate these providers.</p>
</div>
<div class="paragraph">
<p>Using the new CloudForms "migration" tooling we can create mappings between VMware infrastructure and Red Hat Virtualisation. These include clusters, storage and networking. We can then detect the VM&#8217;s currently running in VMware and using virt-v2v under the covers we can automate the migration of those VM&#8217;s across to RHV.</p>
</div>
<div class="paragraph">
<p>This short video shows a demo of the process.</p>
</div>
<div class="videoblock">
<div class="content">
<iframe src="https://www.youtube.com/embed/NdjGuJaDSOU?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2019/01/09/Infrastructure-Migration-Solution.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2019/01/09/Infrastructure-Migration-Solution.html</guid><pubDate>Wed, 09 Jan 2019 00:00:00 GMT</pubDate></item><item><title><![CDATA[RHV Disaster Recovery - Part I]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Since the release of Red Hat Virtualisation (RHV) 4.1 back in 2017 we have seen the inclusion of Disaster Recovery (DR) solutions. The aim of these solutions is to allow customers to deploy their RHV infrastructure to span multiple sites and allow failover of virtual machines in the event of a disaster. This post will take a look at these Disaster Recovery solutions.</p>
</div>
<div class="paragraph">
<p>It is worth noting that these DR solutions are part of the core RHV product and are NOT part of a separate subscription offering. There is no per Virtual Machine (VM) cost or similar charge for protecting your workloads.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_overview">Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>RHV 4.1 was released back in 2017 and we introduced an Active/Active implementation. With the release of RHV 4.2 in May 2018 we introduced additional disaster recovery capabilities. We can now deploy an Active/Passive architecture spanning two sites. Let&#8217;s take a look at the different implementation options.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_active_active">Active/Active</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Active/Active architecture can span two sites. With this implementation we deploy a single RHV cluster with RHV hosts spanning both sites in a stretch cluster configuration. A single RHV Manager is responsible for managing both sites. The RHV Manager itself could be self hosted or standalone (self-hosted simply means the RHV Manager is a VM running on the hypervisors it is managing).</p>
</div>
<div class="paragraph">
<p>As both sites are active at the same time and VM&#8217;s can effectively run at either site at any given time we require synchronously replicated storage that is writeable at both sites at the same time.</p>
</div>
<div class="paragraph">
<p>In addition to the storage replication we also need a stretched network between sites. As we are deploying a single cluster across both sites we need all of the RHV hosts to be in the same Layer 2 network segment. Also VM networks need to be stretched between sites so that that VM&#8217;s can migrate or failover to the secondary site and maintain network connectivity.</p>
</div>
<div class="paragraph">
<p>VM to RHV Host affinity can be used to ensure VM&#8217;s are running in the Primary datacenter where possible and only failed over as part of a disaster. In the event of a disaster in the Primary site, any VM&#8217;s marked as "highly available" will automatically be restarted in the Disaster site without any administrator intervention.</p>
</div>
<div class="paragraph">
<p>The nice thing about the Active/Active setup is that we just rely on native RHV HA to fail VM&#8217;s between sites. It does rely on a storage array that can provide write access to both sites with replication. An example of this would be something like EMC VPLEX.</p>
</div>
<div class="paragraph">
<p>Here is what an Active/Active configuration looks like. This diagram depicts a the RHV manager as a self-hosted engine which is failed over along with the VM workloads.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/RHV%20DR%20Active%20Active%201.png" alt="RHV DR Active Active 1">
</div>
</div>
<div class="paragraph">
<p>In the event of a failure at the Primary site, any VM&#8217;s marked as highly available will automatically restart on RHV hosts in the DR site. Also, as the RHV Manager is self-hosted it is also restarted at the DR site.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/RHV%20DR%20Active%20Active%202.png" alt="RHV DR Active Active 2">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_active_passive">Active/Passive</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Active/Passive configuration can also be used across two sites. As the name suggests, only one site is active at any given time. In the event of a disaster, VM&#8217;s are failed over from the Primary site to the Disaster site. Once the Primary site is recovered we can then failback. Both failover and failback occur in an automated fashion using Ansible.</p>
</div>
<div class="paragraph">
<p>Unlike the Active/Active architecture, each site must maintain its own RHV Manager which manages the RHV hosts, storage and networks for that site.</p>
</div>
<div class="paragraph">
<p>From the storage perspective we require replicated storage between sites. However, the storage is only ever attached to one RHV site at a time so it does not need to be writeable at both sites simultaneously. The same VM networks need to be available in both sites so that VM&#8217;s that are failed over can be re-attached to the network.</p>
</div>
<div class="paragraph">
<p>Here is what an Active/Passive configuration looks like.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/RHV%20DR%20Active%20Passive%201.png" alt="RHV DR Active Passive 1">
</div>
</div>
<div class="paragraph">
<p>In the event of a disaster at the Primary site then we need to ensure that any replication of storage is stopped and that the storage is changed to read/write at the DR site and readonly at Primary site. An administrator can then initiate a failover of VM&#8217;s to the DR site.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://cloudautomation.pharriso.co.uk/images/RHV%20DR%20Active%20Passive%202.png" alt="RHV DR Active Passive 2">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary">Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Since the release of RHV 4.2 we now have two options for providing Disaster Recovery for our VM&#8217;s.</p>
</div>
<div class="paragraph">
<p>The Active/Active configuration allows us to easily fail workloads between sites using VM HA. However, it does rely on storage which is read/write at both sites at the same time as well as being synchronously replicated.</p>
</div>
<div class="paragraph">
<p>The Active/Passive solution only requires replicated storage in read/write at one site at a time. However, failover requires manual intervention to switch storage replication and also initiate the VM failover via Ansible.</p>
</div>
<div class="paragraph">
<p>In the next part of this post we will take a look at how to setup RHV DR in an Active/Passive configuration and how to perform failover and failback.</p>
</div>
</div>
</div>]]></description><link>http://cloudautomation.pharriso.co.uk/2019/01/08/RHV-Disaster-Recovery-Part-I.html</link><guid isPermaLink="true">http://cloudautomation.pharriso.co.uk/2019/01/08/RHV-Disaster-Recovery-Part-I.html</guid><pubDate>Tue, 08 Jan 2019 00:00:00 GMT</pubDate></item></channel></rss>